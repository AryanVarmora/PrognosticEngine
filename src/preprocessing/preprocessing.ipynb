{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Adding RUL column to training data...\n",
      "Normalizing data...\n",
      "Saving preprocessed data...\n",
      "Preprocessing complete!\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing Script for CMAPSS Dataset\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Paths to dataset files (update with actual paths if necessary)\n",
    "DATA_DIR = \"/Users/aryan/Desktop/PrognosticEngine/data\"\n",
    "TRAIN_FILE = os.path.join(DATA_DIR, \"train_FD001.txt\")\n",
    "TEST_FILE = os.path.join(DATA_DIR, \"test_FD001.txt\")\n",
    "RUL_FILE = os.path.join(DATA_DIR, \"RUL_FD001.txt\")\n",
    "\n",
    "# Column names for the dataset\n",
    "COLUMN_NAMES = [\n",
    "    \"engine_id\", \"cycle\", \"operational_setting_1\", \"operational_setting_2\", \n",
    "    \"operational_setting_3\", \"sensor_measurement_1\", \"sensor_measurement_2\", \n",
    "    \"sensor_measurement_3\", \"sensor_measurement_4\", \"sensor_measurement_5\"\n",
    "] + [f\"sensor_measurement_{i}\" for i in range(6, 22)]\n",
    "\n",
    "# Load the data\n",
    "def load_data(file_path, column_names):\n",
    "    \"\"\"Load the dataset into a Pandas DataFrame.\"\"\"\n",
    "    return pd.read_csv(file_path, sep=\" \", header=None, names=column_names, engine='python').dropna(axis=1)\n",
    "\n",
    "# Add Remaining Useful Life (RUL)\n",
    "def add_rul_column(df):\n",
    "    \"\"\"Add a Remaining Useful Life column to the DataFrame.\"\"\"\n",
    "    max_cycle = df.groupby('engine_id')['cycle'].max()\n",
    "    df = df.merge(max_cycle.rename('max_cycle'), on='engine_id')\n",
    "    df['RUL'] = df['max_cycle'] - df['cycle']\n",
    "    return df.drop(columns=['max_cycle'])\n",
    "\n",
    "# Normalize the data\n",
    "def normalize_data(df, columns):\n",
    "    \"\"\"Normalize selected columns in the DataFrame.\"\"\"\n",
    "    for col in columns:\n",
    "        mean = df[col].mean()\n",
    "        std = df[col].std()\n",
    "        df[col] = (df[col] - mean) / std\n",
    "    return df\n",
    "\n",
    "# Save preprocessed data\n",
    "def save_preprocessed_data(df, output_path):\n",
    "    \"\"\"Save the preprocessed DataFrame to a CSV file.\"\"\"\n",
    "    df.to_csv(output_path, index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Loading data...\")\n",
    "    train_df = load_data(TRAIN_FILE, COLUMN_NAMES)\n",
    "    test_df = load_data(TEST_FILE, COLUMN_NAMES)\n",
    "\n",
    "    print(\"Adding RUL column to training data...\")\n",
    "    train_df = add_rul_column(train_df)\n",
    "\n",
    "    print(\"Normalizing data...\")\n",
    "    sensor_columns = [col for col in train_df.columns if 'sensor_measurement' in col]\n",
    "    train_df = normalize_data(train_df, sensor_columns)\n",
    "    test_df = normalize_data(test_df, sensor_columns)\n",
    "\n",
    "    print(\"Saving preprocessed data...\")\n",
    "    save_preprocessed_data(train_df, os.path.join(DATA_DIR, \"train_FD001_preprocessed.csv\"))\n",
    "    save_preprocessed_data(test_df, os.path.join(DATA_DIR, \"test_FD001_preprocessed.csv\"))\n",
    "\n",
    "    print(\"Preprocessing complete!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
